# The config recipe.
# https://rasa.com/docs/rasa/model-configuration/
recipe: default.v1

# The assistant project unique identifier
# This default value must be replaced with a unique assistant name within your deployment
assistant_id: 20240216-235306-dynamic-broadcast

# Configuration for Rasa NLU.
# https://rasa.com/docs/rasa/nlu/components/
language: en

#pipeline:
#- name: "HFTransformersNLP"
#  model_name: "google/word2vec-google-news-300"
#  model_weights: "fse/word2vec-google-news-300"
#- name: "LanguageModelTokenizer"
#- name: "LanguageModelFeaturizer"
  # Add other components as needed for your NLU pipeline

# # No configuration for the NLU pipeline was provided. The following default pipeline was used to train your model.
# # If you'd like to customize it, uncomment and adjust the pipeline.
# # See https://rasa.com/docs/rasa/tuning-your-model for more information.
#   - name: WhitespaceTokenizer
#   - name: RegexFeaturizer
#   - name: LexicalSyntacticFeaturizer
#   - name: CountVectorsFeaturizer
#   - name: CountVectorsFeaturizer
#     analyzer: char_wb
#     min_ngram: 1
#     max_ngram: 4
#   - name: DIETClassifier
#     epochs: 100
#     constrain_similarities: true
#   - name: EntitySynonymMapper
#   - name: ResponseSelector
#     epochs: 100
#     constrain_similarities: true
#   - name: FallbackClassifier
#     threshold: 0.3
#     ambiguity_threshold: 0.1

# Configuration for Rasa Core.
# https://rasa.com/docs/rasa/core/policies/
policies: null
# # No configuration for policies was provided. The following default policies were used to train your model.
# # If you'd like to customize them, uncomment and adjust the policies.
# # See https://rasa.com/docs/rasa/policies for more information.
#   - name: MemoizationPolicy
#   - name: RulePolicy
#   - name: UnexpecTEDIntentPolicy
#     max_history: 5
#     epochs: 100
#   - name: TEDPolicy
#     max_history: 5
#     epochs: 100
#     constrain_similarities: true
pipeline:
# # No configuration for the NLU pipeline was provided. The following default pipeline was used to train your model.
# # If you'd like to customize it, uncomment and adjust the pipeline.
# # See https://rasa.com/docs/rasa/tuning-your-model for more information.
#   - name: WhitespaceTokenizer
#   - name: RegexFeaturizer
#   - name: LexicalSyntacticFeaturizer
#   - name: CountVectorsFeaturizer
#   - name: CountVectorsFeaturizer
#     analyzer: char_wb
#     min_ngram: 1
#     max_ngram: 4
#   - name: DIETClassifier
#     epochs: 100
#     constrain_similarities: true
#   - name: EntitySynonymMapper
#   - name: ResponseSelector
#     epochs: 100
#     constrain_similarities: true
#   - name: FallbackClassifier
#     threshold: 0.3
#     ambiguity_threshold: 0.1

# ----------------------------------------------------

# The configuration you provided in `config.yml` specifies the use of the Hugging Face
# Transformers NLP component (`HFTransformersNLP`) with the Word2Vec model (`google/word2vec-google-news-300`)
# for feature extraction. This configuration will indeed change the behavior of your NLU pipeline, but it won't
# directly enable computing similarity between user input and your dataset.
#
#Here's what happens with this configuration:
#
#1. **HFTransformersNLP Component**:
# The `HFTransformersNLP` component uses pre-trained language models from Hugging Face's model hub.
# In this case, you're specifying the Word2Vec model (`google/word2vec-google-news-300`). However, it's important to note that the Word2Vec model is not a Transformer-based model like BERT or GPT, which are commonly used with the `HFTransformersNLP` component. Therefore, using the Word2Vec model with this component might not provide optimal results because the component is designed for Transformer-based models.
#
#2. **LanguageModelTokenizer and LanguageModelFeaturizer**: These components tokenize the input text and extract features from it using the specified language model. Since Word2Vec is not a Transformer-based model, these components may not be able to tokenize the input text and extract features properly.
#
#To compute similarity between user input and your dataset using a Word2Vec model, you typically need to:
#
#- Load the Word2Vec model separately in your custom action code.
#- Preprocess the user input and compute embeddings for it using the Word2Vec model.
#- Compute similarity between the user input embeddings and the embeddings of your dataset.
#
#Changing the configuration in `config.yml` alone won't handle these tasks. You would still need to implement the similarity computation logic in your custom action code, as shown in previous examples.