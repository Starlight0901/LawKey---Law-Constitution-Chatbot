{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim\n",
        "\n",
        "from gensim.downloader import load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUCR1tCngVoV",
        "outputId": "e7f0feb6-fbd1-4812-8a9b-6716233d1afc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained word2vec model (may take some time to download)\n",
        "word_model = load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "EPIxKwTSAVN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcff476-d1e2-4f09-e290-da38362104b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def law_cleaning(law):\n",
        "    # Remove punctuations\n",
        "    law = law.translate(str.maketrans('', '', string.punctuation + '\\r\\n\\t'))\n",
        "\n",
        "    # Remove special characters\n",
        "    law = law.replace('ã', '')\n",
        "    law = law.replace('Ã', '')\n",
        "\n",
        "    # Remain only the alphabetic, numeric characters and whitespaces\n",
        "    law = ''.join([i for i in law if i.isalnum() or i.isspace()])\n",
        "    return law\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered = [token for token in tokens if token.lower() not in stop_words]\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def stemmer(tokens):\n",
        "    # Create the Porter stemmer object\n",
        "    pstemmer = PorterStemmer()\n",
        "    stemmed_words = [pstemmer.stem(token) for token in tokens]\n",
        "    # Join the list of stemmed words into a single string separated by spaces\n",
        "    stemmed_text = ' '.join(stemmed_words)\n",
        "    return stemmed_text"
      ],
      "metadata": {
        "id": "dqgpaSOkkqc4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your CSV files containing Law Text and User Queries\n",
        "df_law = pd.read_csv(\"dataset.csv\")\n",
        "df_query = pd.read_csv(\"SampleQueries.csv\")"
      ],
      "metadata": {
        "id": "8Va4A5KJkt8v"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess law data for efficiency\n",
        "vectorized = TfidfVectorizer(stop_words=stopwords.words(\"english\"))\n",
        "doc_vectors_tfidf = vectorized.fit_transform(df_law[\"Law\"])\n",
        "\n",
        "law_vectors_word2vec = []\n",
        "for law in df_law[\"Law\"]:\n",
        "    law_tokens = tokenize(law_cleaning(law))\n",
        "    law_tokens = remove_stopwords(law_tokens)\n",
        "    law_vector = np.mean([word_model[word] for word in law_tokens if word in word_model], axis=0)\n",
        "    law_vectors_word2vec.append(law_vector)\n",
        "\n",
        "\n",
        "# Loop through each user query in the dataframe\n",
        "for index, row in df_query.iterrows():\n",
        "  user_query = row[\"Queries\"]\n",
        "\n",
        "  # Preprocess user input\n",
        "  cleaned_text = law_cleaning(user_query)\n",
        "  tokens = tokenize(cleaned_text)\n",
        "  tokens = remove_stopwords(tokens)\n",
        "  processed_text = stemmer(tokens)\n",
        "\n",
        "  # Calculate similarity using both TF-IDF and Word2Vec\n",
        "  input_vector_tfidf = vectorized.transform([processed_text])\n",
        "  similarities_tfidf = cosine_similarity(input_vector_tfidf, doc_vectors_tfidf)[0]\n",
        "\n",
        "  input_vector_word2vec = np.mean([word_model[word] for word in tokens if word in word_model], axis=0)\n",
        "  similarities_word2vec = cosine_similarity([input_vector_word2vec], law_vectors_word2vec)[0]\n",
        "\n",
        "  # Combine similarities (simple average)\n",
        "  combined_similarities = (similarities_tfidf + similarities_word2vec) / 2\n",
        "  highest_similarity = max(combined_similarities)\n",
        "\n",
        "  # Update 'Highest Similarity Value' column for the current query\n",
        "  df_query.at[index, 'Highest Similarity Value'] = highest_similarity"
      ],
      "metadata": {
        "id": "dXd-hwcAk4Wu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated DataFrame to a new CSV file\n",
        "df_query.to_csv(\"UpdatedSampleQueries.csv\", index=False)"
      ],
      "metadata": {
        "id": "yVWbzXjHU8_b"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter in-scope queries (Ground Truth Label = 1)\n",
        "in_scope_data = df_query[df_query['Ground Truth label'] == 1]\n",
        "\n",
        "# Calculate average highest similarity value for in-scope queries\n",
        "avg_similarity = in_scope_data['Highest Similarity Value'].mean()\n",
        "\n",
        "print(f\"Average Highest Similarity Value (In-Scope Queries): {avg_similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH8laYR7EMqB",
        "outputId": "04b954b9-c182-4670-8039-c19c4fd0fbe1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Highest Similarity Value (In-Scope Queries): 0.5960439917894649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter in-scope queries (Ground Truth Label = 1)\n",
        "in_scope_data = df_query[df_query['Ground Truth label'] == 0]\n",
        "\n",
        "# Calculate average highest similarity value for in-scope queries\n",
        "avg_similarity = in_scope_data['Highest Similarity Value'].mean()\n",
        "\n",
        "print(f\"Average Highest Similarity Value (Out-Scope Queries): {avg_similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eqxGXatWkCf",
        "outputId": "820f3af5-5351-458f-d876-b14aa9d173f1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Highest Similarity Value (Out-Scope Queries): 0.4383325072548749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average highest similarity value for all queries\n",
        "avg_similarity = df_query['Highest Similarity Value'].mean()\n",
        "\n",
        "print(f\"Average Highest Similarity Value (All Queries): {avg_similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MOevsjAFP79",
        "outputId": "065e70c7-4e2f-4f46-bbb7-0a4bd1f22ffd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Highest Similarity Value (All Queries): 0.5171882495221699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_query.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "EFOLWviStLNX",
        "outputId": "cbb1f31b-28ad-43d5-adbb-e27673bbed81"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Queries  Ground Truth label  \\\n",
              "468  How does the court proceed after determining t...                   0   \n",
              "63   Describe the responsibilities concerning the p...                   1   \n",
              "241  What constitutes the territory of the Republic...                   1   \n",
              "73   What are the statutory disqualifications outli...                   1   \n",
              "327  Is Parliament endowed with the authority to en...                   1   \n",
              "190  In cases of inconsistency or conflict with oth...                   1   \n",
              "592  According to Regulation 41, where are the rate...                   0   \n",
              "165  Explain the procedures outlined in the recent ...                   1   \n",
              "261  How does the law regulate the use of Sinhala a...                   1   \n",
              "676         How are trials conducted in Primary Courts                   0   \n",
              "\n",
              "     Highest Similarity Value Unnamed: 3  \n",
              "468                  0.422933        NaN  \n",
              "63                   0.538181        NaN  \n",
              "241                  0.546255        NaN  \n",
              "73                   0.466990        NaN  \n",
              "327                  0.583574        NaN  \n",
              "190                  0.658508        NaN  \n",
              "592                  0.329553        NaN  \n",
              "165                  0.555503        NaN  \n",
              "261                  0.581492        NaN  \n",
              "676                  0.550708        NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbc0a252-59b9-436d-bf33-7f155be00ff5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Queries</th>\n",
              "      <th>Ground Truth label</th>\n",
              "      <th>Highest Similarity Value</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>How does the court proceed after determining t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.422933</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Describe the responsibilities concerning the p...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.538181</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>What constitutes the territory of the Republic...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.546255</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>What are the statutory disqualifications outli...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.466990</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>Is Parliament endowed with the authority to en...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.583574</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>In cases of inconsistency or conflict with oth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.658508</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592</th>\n",
              "      <td>According to Regulation 41, where are the rate...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.329553</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>Explain the procedures outlined in the recent ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.555503</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>How does the law regulate the use of Sinhala a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.581492</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>676</th>\n",
              "      <td>How are trials conducted in Primary Courts</td>\n",
              "      <td>0</td>\n",
              "      <td>0.550708</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbc0a252-59b9-436d-bf33-7f155be00ff5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fbc0a252-59b9-436d-bf33-7f155be00ff5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fbc0a252-59b9-436d-bf33-7f155be00ff5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7f608d1-8510-4dcc-82be-0902dafc52ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7f608d1-8510-4dcc-82be-0902dafc52ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7f608d1-8510-4dcc-82be-0902dafc52ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "f-_qbM39mWlS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe is named 'df_query' with columns:\n",
        "#  - Queries (text)\n",
        "#  - Ground Truth Label (0 - Out-of-Scope, 1 - In-Scope)\n",
        "#  - Highest Similarity Value (float)\n",
        "# Filter data for labeled queries\n",
        "labeled_data = df_query[df_query['Ground Truth label'].notna()]\n",
        "\n",
        "# Separate labels and similarity values\n",
        "y_true = labeled_data['Ground Truth label']\n",
        "# the ground truth label for each query (0 for out-of-scope, 1 for in-scope)\n",
        "y_pred = labeled_data['Highest Similarity Value']\n",
        "# the highest similarity scores obtained for each query after comparing them with the laws"
      ],
      "metadata": {
        "id": "k3JhLvLMme3E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.47\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV0S_ckkLTvS",
        "outputId": "3c5399dd-277d-4669-9e11-7e0e647b43c5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       289                       117\n",
            "Out-of-Scope (Actual)                    21                       385\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.71      0.81       406\n",
            "           1       0.77      0.95      0.85       406\n",
            "\n",
            "    accuracy                           0.83       812\n",
            "   macro avg       0.85      0.83      0.83       812\n",
            "weighted avg       0.85      0.83      0.83       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.48\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skJX2tJuLUxx",
        "outputId": "d73fc779-7ff6-416c-fe77-e07c64e6ce75"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       309                        97\n",
            "Out-of-Scope (Actual)                    30                       376\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.76      0.83       406\n",
            "           1       0.79      0.93      0.86       406\n",
            "\n",
            "    accuracy                           0.84       812\n",
            "   macro avg       0.85      0.84      0.84       812\n",
            "weighted avg       0.85      0.84      0.84       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.49\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_gLeBdyLVoM",
        "outputId": "a5496d09-c0c9-499c-e65e-f5863ad109f3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       324                        82\n",
            "Out-of-Scope (Actual)                    39                       367\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.80      0.84       406\n",
            "           1       0.82      0.90      0.86       406\n",
            "\n",
            "    accuracy                           0.85       812\n",
            "   macro avg       0.85      0.85      0.85       812\n",
            "weighted avg       0.85      0.85      0.85       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.5\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_PL1KNuLiXK",
        "outputId": "fd0e25b4-1f05-4207-80c5-dae0b3ac4466"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       338                        68\n",
            "Out-of-Scope (Actual)                    49                       357\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.83      0.85       406\n",
            "           1       0.84      0.88      0.86       406\n",
            "\n",
            "    accuracy                           0.86       812\n",
            "   macro avg       0.86      0.86      0.86       812\n",
            "weighted avg       0.86      0.86      0.86       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.509\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4eZsSkOUJ9-",
        "outputId": "80d65e8b-fca4-4076-aea0-ca5ea67d7307"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       346                        60\n",
            "Out-of-Scope (Actual)                    55                       351\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.86       406\n",
            "           1       0.85      0.86      0.86       406\n",
            "\n",
            "    accuracy                           0.86       812\n",
            "   macro avg       0.86      0.86      0.86       812\n",
            "weighted avg       0.86      0.86      0.86       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.51\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmXvDfPUTaRl",
        "outputId": "2f3b6194-4b9b-43bb-ffc3-dfb76ae304c8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       350                        56\n",
            "Out-of-Scope (Actual)                    56                       350\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       406\n",
            "           1       0.86      0.86      0.86       406\n",
            "\n",
            "    accuracy                           0.86       812\n",
            "   macro avg       0.86      0.86      0.86       812\n",
            "weighted avg       0.86      0.86      0.86       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.511\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBoGbe9oT_nv",
        "outputId": "cc7c96db-1b4e-4f5b-b672-368a32ad8714"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       350                        56\n",
            "Out-of-Scope (Actual)                    59                       347\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       406\n",
            "           1       0.86      0.85      0.86       406\n",
            "\n",
            "    accuracy                           0.86       812\n",
            "   macro avg       0.86      0.86      0.86       812\n",
            "weighted avg       0.86      0.86      0.86       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.52\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edVWwXe4Te6f",
        "outputId": "cb70480a-3eab-4db3-d013-9dead03abf63"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       358                        48\n",
            "Out-of-Scope (Actual)                    69                       337\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       406\n",
            "           1       0.88      0.83      0.85       406\n",
            "\n",
            "    accuracy                           0.86       812\n",
            "   macro avg       0.86      0.86      0.86       812\n",
            "weighted avg       0.86      0.86      0.86       812\n",
            "\n"
          ]
        }
      ]
    }
  ]
}