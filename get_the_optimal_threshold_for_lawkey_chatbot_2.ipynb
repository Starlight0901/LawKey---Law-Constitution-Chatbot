{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim\n",
        "\n",
        "from gensim.downloader import load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUCR1tCngVoV",
        "outputId": "f82c122f-7ff0-4703-d382-8f80d8673bdf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained word2vec model (may take some time to download)\n",
        "word_model = load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "EPIxKwTSAVN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a87567f-b37f-4334-e822-4ac97514ea1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def law_cleaning(law):\n",
        "    # Remove punctuations\n",
        "    law = law.translate(str.maketrans('', '', string.punctuation + '\\r\\n\\t'))\n",
        "\n",
        "    # Remove special characters\n",
        "    law = law.replace('ã', '')\n",
        "    law = law.replace('Ã', '')\n",
        "\n",
        "    # Remain only the alphabetic, numeric characters and whitespaces\n",
        "    law = ''.join([i for i in law if i.isalnum() or i.isspace()])\n",
        "    return law\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered = [token for token in tokens if token.lower() not in stop_words]\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def stemmer(tokens):\n",
        "    # Create the Porter stemmer object\n",
        "    pstemmer = PorterStemmer()\n",
        "    stemmed_words = [pstemmer.stem(token) for token in tokens]\n",
        "    # Join the list of stemmed words into a single string separated by spaces\n",
        "    stemmed_text = ' '.join(stemmed_words)\n",
        "    return stemmed_text"
      ],
      "metadata": {
        "id": "dqgpaSOkkqc4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your CSV files containing Law Text and User Queries\n",
        "df_law = pd.read_csv(\"dataset.csv\")\n",
        "df_query = pd.read_csv(\"SQ.csv\") # SampleQueries.csv"
      ],
      "metadata": {
        "id": "8Va4A5KJkt8v"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess law data for efficiency\n",
        "vectorized = TfidfVectorizer(stop_words=stopwords.words(\"english\"))\n",
        "doc_vectors_tfidf = vectorized.fit_transform(df_law[\"Law\"])\n",
        "\n",
        "law_vectors_word2vec = []\n",
        "for law in df_law[\"Law\"]:\n",
        "    law_tokens = tokenize(law_cleaning(law))\n",
        "    law_tokens = remove_stopwords(law_tokens)\n",
        "    law_vector = np.mean([word_model[word] for word in law_tokens if word in word_model], axis=0)\n",
        "    law_vectors_word2vec.append(law_vector)\n",
        "\n",
        "\n",
        "# Loop through each user query in the dataframe\n",
        "for index, row in df_query.iterrows():\n",
        "  user_query = row[\"Queries\"]\n",
        "\n",
        "  # Preprocess user input\n",
        "  cleaned_text = law_cleaning(user_query)\n",
        "  tokens = tokenize(cleaned_text)\n",
        "  tokens = remove_stopwords(tokens)\n",
        "  processed_text = stemmer(tokens)\n",
        "\n",
        "  # Calculate similarity using both TF-IDF and Word2Vec\n",
        "  input_vector_tfidf = vectorized.transform([processed_text])\n",
        "  similarities_tfidf = cosine_similarity(input_vector_tfidf, doc_vectors_tfidf)[0]\n",
        "\n",
        "  input_vector_word2vec = np.mean([word_model[word] for word in tokens if word in word_model], axis=0)\n",
        "  similarities_word2vec = cosine_similarity([input_vector_word2vec], law_vectors_word2vec)[0]\n",
        "\n",
        "  # Combine similarities (simple average)\n",
        "  combined_similarities = (similarities_tfidf + similarities_word2vec) / 2\n",
        "  highest_similarity = max(combined_similarities)\n",
        "\n",
        "  # Update 'Highest Similarity Value' column for the current query\n",
        "  df_query.at[index, 'Highest Similarity Value'] = highest_similarity"
      ],
      "metadata": {
        "id": "dXd-hwcAk4Wu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated DataFrame to a new CSV file\n",
        "df_query.to_csv(\"UpdatedSampleQueries.csv\", index=False)"
      ],
      "metadata": {
        "id": "yVWbzXjHU8_b"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter in-scope queries (Ground Truth Label = 1)\n",
        "in_scope_data = df_query[df_query['Ground Truth label'] == 1]\n",
        "\n",
        "# Calculate average highest similarity value for in-scope queries\n",
        "avg_similarity = in_scope_data['Highest Similarity Value'].mean()\n",
        "\n",
        "print(f\"Average Highest Similarity Value (In-Scope Queries): {avg_similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH8laYR7EMqB",
        "outputId": "6a7f7db2-c969-4b6c-b4a9-968c0bcccea1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Highest Similarity Value (In-Scope Queries): 0.5960439917894649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter in-scope queries (Ground Truth Label = 1)\n",
        "in_scope_data = df_query[df_query['Ground Truth label'] == 0]\n",
        "\n",
        "# Calculate average highest similarity value for in-scope queries\n",
        "avg_similarity = in_scope_data['Highest Similarity Value'].mean()\n",
        "\n",
        "print(f\"Average Highest Similarity Value (Out-Scope Queries): {avg_similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eqxGXatWkCf",
        "outputId": "acc2bbb3-a410-40de-bdbe-60cdd0087c98"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Highest Similarity Value (Out-Scope Queries): 0.4260699359696492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average highest similarity value for all queries\n",
        "avg_similarity = df_query['Highest Similarity Value'].mean()\n",
        "\n",
        "print(f\"Average Highest Similarity Value (All Queries): {avg_similarity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MOevsjAFP79",
        "outputId": "21831952-1b24-4102-ab5d-9ae35bdde5bb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Highest Similarity Value (All Queries): 0.5110569638795571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_query.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EFOLWviStLNX",
        "outputId": "e91814ae-5709-4a7a-ae20-1d0ac22375fd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Queries  Ground Truth label  \\\n",
              "57   Explain the entitlement for protection where a...                   1   \n",
              "321  Does Parliament possess the authority to opera...                   1   \n",
              "592  How are international telecommunications regul...                   0   \n",
              "101  Which specific matters related to interim awar...                   1   \n",
              "43   Explain the rights and entitlements of witness...                   1   \n",
              "791  How do international laws address the rights o...                   0   \n",
              "306  Upon delegation of any of its powers to a Comm...                   1   \n",
              "279  How is the Constitutional Council in Sri Lanka...                   1   \n",
              "55   Explain the provisions of the specified Act re...                   1   \n",
              "566  What happens in a Primary Court if the Judge i...                   0   \n",
              "\n",
              "     Highest Similarity Value  \n",
              "57                   0.672091  \n",
              "321                  0.493180  \n",
              "592                  0.353057  \n",
              "101                  0.768304  \n",
              "43                   0.578429  \n",
              "791                  0.383689  \n",
              "306                  0.718322  \n",
              "279                  0.599794  \n",
              "55                   0.500098  \n",
              "566                  0.390740  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60bb09a5-0577-43ee-b1e0-76ae4fd59c09\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Queries</th>\n",
              "      <th>Ground Truth label</th>\n",
              "      <th>Highest Similarity Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Explain the entitlement for protection where a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.672091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>Does Parliament possess the authority to opera...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.493180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592</th>\n",
              "      <td>How are international telecommunications regul...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.353057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Which specific matters related to interim awar...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.768304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Explain the rights and entitlements of witness...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.578429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>How do international laws address the rights o...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.383689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Upon delegation of any of its powers to a Comm...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.718322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>How is the Constitutional Council in Sri Lanka...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.599794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Explain the provisions of the specified Act re...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.500098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>What happens in a Primary Court if the Judge i...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.390740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60bb09a5-0577-43ee-b1e0-76ae4fd59c09')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60bb09a5-0577-43ee-b1e0-76ae4fd59c09 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60bb09a5-0577-43ee-b1e0-76ae4fd59c09');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f47d24b1-9352-4ea8-b9b7-d0da32fb0cf9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f47d24b1-9352-4ea8-b9b7-d0da32fb0cf9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f47d24b1-9352-4ea8-b9b7-d0da32fb0cf9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_query\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Queries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Explain the provisions of the specified Act regarding the offense of providing false information, emphasizing the importance of intent in the act. Explore the conditions under which an individual may be considered in violation, specifically when they knowingly or have reasonable grounds to believe that the information provided is false. Discuss the entities involved, including the Authority, Police, Protection Division, courts, or Commissions, from which the individual seeks assistance or protection through the submission of false information. Additionally, elaborate on the severity of the offense, as reflected in the potential consequences upon conviction by the High Court, which may include fines not exceeding five hundred thousand rupees, imprisonment for a period not exceeding six years, or a combination of both. Highlight the significance of this provision in maintaining the integrity of the legal process and ensuring that information provided for assistance or protection is truthful and reliable.\",\n          \"Does Parliament possess the authority to operate and conduct its proceedings without hindrance, even in the presence of vacancies in its membership, and are the proceedings considered valid even if it is later discovered that an individual who was not entitled to do so participated in sitting, voting, or other aspects of the proceedings?\",\n          \"How do international laws address the rights of refugees and asylum seekers to family reunification and protection from deportation, including issues of family separation, visa processing, and border controls?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ground Truth label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Highest Similarity Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14588128504134873,\n        \"min\": 0.35305700312547306,\n        \"max\": 0.7683039216748578,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5000983879490638,\n          0.4931801482576787\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "f-_qbM39mWlS"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe is named 'df_query' with columns:\n",
        "#  - Queries (text)\n",
        "#  - Ground Truth Label (0 - Out-of-Scope, 1 - In-Scope)\n",
        "#  - Highest Similarity Value (float)\n",
        "# Filter data for labeled queries\n",
        "labeled_data = df_query[df_query['Ground Truth label'].notna()]\n",
        "\n",
        "# Separate labels and similarity values\n",
        "y_true = labeled_data['Ground Truth label']\n",
        "# the ground truth label for each query (0 for out-of-scope, 1 for in-scope)\n",
        "y_pred = labeled_data['Highest Similarity Value']\n",
        "# the highest similarity scores obtained for each query after comparing them with the laws"
      ],
      "metadata": {
        "id": "k3JhLvLMme3E"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.47\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(\"Threshold: \",threshold)\n",
        "\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV0S_ckkLTvS",
        "outputId": "0733a2a5-ba4f-41f8-c5cc-e225d25fd227"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.47\n",
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       321                        85\n",
            "Out-of-Scope (Actual)                    21                       385\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.79      0.86       406\n",
            "           1       0.82      0.95      0.88       406\n",
            "\n",
            "    accuracy                           0.87       812\n",
            "   macro avg       0.88      0.87      0.87       812\n",
            "weighted avg       0.88      0.87      0.87       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.48\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(\"Threshold: \",threshold)\n",
        "\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skJX2tJuLUxx",
        "outputId": "f78f1f0f-256b-435c-e631-5b3f205f4a99"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.48\n",
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       341                        65\n",
            "Out-of-Scope (Actual)                    30                       376\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88       406\n",
            "           1       0.85      0.93      0.89       406\n",
            "\n",
            "    accuracy                           0.88       812\n",
            "   macro avg       0.89      0.88      0.88       812\n",
            "weighted avg       0.89      0.88      0.88       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.49\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(\"Threshold: \",threshold)\n",
        "\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_gLeBdyLVoM",
        "outputId": "84294452-77a4-4f94-9252-060535c9726a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.49\n",
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       351                        55\n",
            "Out-of-Scope (Actual)                    39                       367\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88       406\n",
            "           1       0.87      0.90      0.89       406\n",
            "\n",
            "    accuracy                           0.88       812\n",
            "   macro avg       0.88      0.88      0.88       812\n",
            "weighted avg       0.88      0.88      0.88       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.498\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(\"Threshold: \",threshold)\n",
        "\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_qHgWEGtBfS",
        "outputId": "07053d90-b170-438e-ed15-6b60e2aefe3c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.498\n",
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       358                        48\n",
            "Out-of-Scope (Actual)                    46                       360\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.88       406\n",
            "           1       0.88      0.89      0.88       406\n",
            "\n",
            "    accuracy                           0.88       812\n",
            "   macro avg       0.88      0.88      0.88       812\n",
            "weighted avg       0.88      0.88      0.88       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.4988\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(\"Threshold: \",threshold)\n",
        "\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OgitL_8tF8-",
        "outputId": "2d47eee2-0617-4a46-de44-29554aa03aab"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.4988\n",
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       360                        46\n",
            "Out-of-Scope (Actual)                    46                       360\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       406\n",
            "           1       0.89      0.89      0.89       406\n",
            "\n",
            "    accuracy                           0.89       812\n",
            "   macro avg       0.89      0.89      0.89       812\n",
            "weighted avg       0.89      0.89      0.89       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.499\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(\"Threshold: \",threshold)\n",
        "\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbHrx4U_s2M4",
        "outputId": "773c50ec-9364-46fd-d45a-73fb9da9d513"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.499\n",
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       362                        44\n",
            "Out-of-Scope (Actual)                    48                       358\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89       406\n",
            "           1       0.89      0.88      0.89       406\n",
            "\n",
            "    accuracy                           0.89       812\n",
            "   macro avg       0.89      0.89      0.89       812\n",
            "weighted avg       0.89      0.89      0.89       812\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a threshold based on your risk tolerance and application needs.\n",
        "threshold = 0.5\n",
        "\n",
        "# Classify queries based on the threshold\n",
        "labeled_data['Predicted Label'] = labeled_data['Highest Similarity Value'].apply(lambda x: 1 if x >= threshold else 0)\n",
        "\n",
        "# Evaluate performance metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, labeled_data['Predicted Label']),\n",
        "                                 index=['In-Scope (Actual)', 'Out-of-Scope (Actual)'],\n",
        "                                 columns=['In-Scope (Predicted)', 'Out-of-Scope (Predicted)'])\n",
        "print(\"Threshold: \",threshold)\n",
        "\n",
        "print(confusion_matrix_df)\n",
        "\n",
        "print(classification_report(y_true, labeled_data['Predicted Label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_PL1KNuLiXK",
        "outputId": "bae7ff59-a1f2-4c90-de68-628529967500"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.5\n",
            "                       In-Scope (Predicted)  Out-of-Scope (Predicted)\n",
            "In-Scope (Actual)                       362                        44\n",
            "Out-of-Scope (Actual)                    49                       357\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89       406\n",
            "           1       0.89      0.88      0.88       406\n",
            "\n",
            "    accuracy                           0.89       812\n",
            "   macro avg       0.89      0.89      0.89       812\n",
            "weighted avg       0.89      0.89      0.89       812\n",
            "\n"
          ]
        }
      ]
    }
  ]
}